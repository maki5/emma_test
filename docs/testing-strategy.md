# Testing Strategy

## Overview

Testing is done at multiple levels:
1. **Unit Tests** - Per-layer tests with mocks (using mockery)
2. **Integration Tests** - Repository tests with real PostgreSQL (using testcontainers)
3. **E2E Tests** - Bash scripts with curl for API testing

---

## Test Data Location

Test data files are pre-generated and stored in the `testdata/` folder at the project root:

```
bulk-import-export/
‚îú‚îÄ‚îÄ testdata/                      # Pre-generated test data files
‚îÇ   ‚îú‚îÄ‚îÄ users_huge.csv             # 10,000 user records
‚îÇ   ‚îú‚îÄ‚îÄ articles_huge.ndjson       # 15,000 article records
‚îÇ   ‚îî‚îÄ‚îÄ comments_huge.ndjson       # 20,000 comment records
‚îú‚îÄ‚îÄ internal/
‚îú‚îÄ‚îÄ cmd/
‚îî‚îÄ‚îÄ ...
```

### Test Data Files

| File | Records | Format | Description |
|------|---------|--------|-------------|
| `testdata/users_huge.csv` | 10,000 | CSV | User records with id, email, name, role |
| `testdata/articles_huge.ndjson` | 15,000 | NDJSON | Article records with id, author_id, tags, status |
| `testdata/comments_huge.ndjson` | 20,000 | NDJSON | Comment records with id, article_id, user_id |

**Total**: 45,000 records for comprehensive testing.

> **Important**: All test data records include pre-generated UUIDs in the `id` field. These IDs are used directly when inserting/upserting records into the database. This enables:
> - Predictable test data for verification
> - Upsert operations using the provided ID
> - Referential integrity (articles reference user IDs, comments reference article/user IDs)

---

## Unit Tests (mockery)

Unit tests are written for each layer with mocks generated by [mockery](https://github.com/vektra/mockery).

### Install Mockery

```bash
go install github.com/vektra/mockery/v2@latest
```

### Generate Mocks

```bash
# Generate mocks for all interfaces
mockery --all --dir=internal --output=internal/mocks --outpkg=mocks

# Or generate specific mocks
mockery --name=UserRepository --dir=internal/repository --output=internal/mocks
mockery --name=ImportService --dir=internal/service --output=internal/mocks
```

### Mock Configuration

```yaml
# .mockery.yaml
with-expecter: true
dir: internal
output: internal/mocks
outpkg: mocks
all: true
interfaces:
  - UserRepository
  - ArticleRepository
  - CommentRepository
  - JobRepository
  - ImportService
  - ExportService
```

### Handler Layer Tests

```go
// internal/handler/import_handler_test.go
package handler_test

import (
	"bytes"
	"mime/multipart"
	"net/http"
	"net/http/httptest"
	"testing"

	"github.com/gin-gonic/gin"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/mock"

	"bulk-import-export/internal/handler"
	"bulk-import-export/internal/mocks"
)

func TestImportHandler_CreateImport_Success(t *testing.T) {
	// Arrange
	mockService := mocks.NewMockImportService(t)
	h := handler.NewImportHandler(mockService)

	mockService.EXPECT().
		CreateImportJob(mock.Anything, mock.Anything).
		Return(&domain.Job{ID: "job-123", Status: "pending"}, nil)

	// Create multipart request
	body := &bytes.Buffer{}
	writer := multipart.NewWriter(body)
	part, _ := writer.CreateFormFile("file", "users.csv")
	part.Write([]byte("id,email,name\n"))
	writer.WriteField("resource", "users")
	writer.Close()

	req := httptest.NewRequest(http.MethodPost, "/v1/imports", body)
	req.Header.Set("Content-Type", writer.FormDataContentType())
	req.Header.Set("Idempotency-Key", "test-key")

	w := httptest.NewRecorder()
	c, _ := gin.CreateTestContext(w)
	c.Request = req

	// Act
	h.CreateImport(c)

	// Assert
	assert.Equal(t, http.StatusAccepted, w.Code)
	mockService.AssertExpectations(t)
}

func TestImportHandler_CreateImport_InvalidResource(t *testing.T) {
	// Arrange
	mockService := mocks.NewMockImportService(t)
	h := handler.NewImportHandler(mockService)

	body := &bytes.Buffer{}
	writer := multipart.NewWriter(body)
	part, _ := writer.CreateFormFile("file", "invalid.csv")
	part.Write([]byte("data"))
	writer.WriteField("resource", "invalid_resource")
	writer.Close()

	req := httptest.NewRequest(http.MethodPost, "/v1/imports", body)
	req.Header.Set("Content-Type", writer.FormDataContentType())

	w := httptest.NewRecorder()
	c, _ := gin.CreateTestContext(w)
	c.Request = req

	// Act
	h.CreateImport(c)

	// Assert
	assert.Equal(t, http.StatusBadRequest, w.Code)
}
```

### Service Layer Tests

```go
// internal/service/import_service_test.go
package service_test

import (
	"context"
	"testing"

	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/mock"

	"bulk-import-export/internal/domain"
	"bulk-import-export/internal/mocks"
	"bulk-import-export/internal/service"
)

func TestImportService_ProcessBatch_Success(t *testing.T) {
	// Arrange
	mockUserRepo := mocks.NewMockUserRepository(t)
	mockJobRepo := mocks.NewMockJobRepository(t)

	svc := service.NewImportService(
		service.WithUserRepository(mockUserRepo),
		service.WithJobRepository(mockJobRepo),
	)

	users := []domain.User{
		{ID: "1", Email: "a@test.com", Name: "User A"},
		{ID: "2", Email: "b@test.com", Name: "User B"},
	}

	mockUserRepo.EXPECT().
		BulkInsertWithCTE(mock.Anything, users).
		Return(&domain.BatchResult{Successful: 2, Errors: nil}, nil)

	mockJobRepo.EXPECT().
		UpdateProgress(mock.Anything, mock.Anything).
		Return(nil)

	// Act
	result, err := svc.ProcessBatch(context.Background(), "job-1", users)

	// Assert
	assert.NoError(t, err)
	assert.Equal(t, 2, result.Successful)
	assert.Empty(t, result.Errors)
}

func TestImportService_ProcessBatch_PartialFailure(t *testing.T) {
	// Arrange
	mockUserRepo := mocks.NewMockUserRepository(t)
	mockJobRepo := mocks.NewMockJobRepository(t)

	svc := service.NewImportService(
		service.WithUserRepository(mockUserRepo),
		service.WithJobRepository(mockJobRepo),
	)

	users := []domain.User{
		{ID: "1", Email: "valid@test.com", Name: "Valid"},
		{ID: "2", Email: "duplicate@test.com", Name: "Duplicate"},
	}

	mockUserRepo.EXPECT().
		BulkInsertWithCTE(mock.Anything, users).
		Return(&domain.BatchResult{
			Successful: 1,
			Errors: []domain.RecordError{
				{Row: 2, Field: "email", Value: "duplicate@test.com", Reason: "duplicate_email"},
			},
		}, nil)

	mockJobRepo.EXPECT().
		UpdateProgress(mock.Anything, mock.Anything).
		Return(nil)

	// Act
	result, err := svc.ProcessBatch(context.Background(), "job-1", users)

	// Assert
	assert.NoError(t, err)
	assert.Equal(t, 1, result.Successful)
	assert.Len(t, result.Errors, 1)
}
```

---

## Integration Tests (testcontainers)

Repository tests run against a real PostgreSQL database using [testcontainers-go](https://golang.testcontainers.org/).

### Install Testcontainers

```bash
go get github.com/testcontainers/testcontainers-go
go get github.com/testcontainers/testcontainers-go/modules/postgres
```

### Test Database Setup

```go\n// internal/repository/testutil/postgres_container.go
package testutil

import (
	\"context\"
	\"os\"
	\"path/filepath\"
	\"sort\"
	\"strings\"
	\"testing\"
	\"time\"

	\"github.com/jackc/pgx/v5/pgxpool\"
	\"github.com/testcontainers/testcontainers-go\"
	\"github.com/testcontainers/testcontainers-go/modules/postgres\"
	\"github.com/testcontainers/testcontainers-go/wait\"
)

type PostgresContainer struct {
	Container testcontainers.Container
	Pool      *pgxpool.Pool
	DSN       string
}

func SetupPostgresContainer(t *testing.T) *PostgresContainer {
	t.Helper()
	ctx := context.Background()

	container, err := postgres.Run(ctx,
		\"postgres:15\",
		postgres.WithDatabase(\"test_db\"),
		postgres.WithUsername(\"test\"),
		postgres.WithPassword(\"test\"),
		testcontainers.WithWaitStrategy(
			wait.ForLog(\"database system is ready to accept connections\").
				WithOccurrence(2).
				WithStartupTimeout(30*time.Second)),
	)
	if err != nil {
		t.Fatalf(\"failed to start postgres container: %v\", err)
	}

	// Cleanup on test end
	t.Cleanup(func() {
		if err := container.Terminate(ctx); err != nil {
			t.Logf(\"failed to terminate container: %v\", err)
		}
	})

	// Get connection string
	dsn, err := container.ConnectionString(ctx, \"sslmode=disable\")
	if err != nil {
		t.Fatalf(\"failed to get connection string: %v\", err)
	}

	// Create connection pool
	pool, err := pgxpool.New(ctx, dsn)
	if err != nil {
		t.Fatalf(\"failed to create pool: %v\", err)
	}
	t.Cleanup(func() { pool.Close() })

	// Run migrations from files (ensures test schema matches production)
	if err := RunMigrationsFromFiles(ctx, pool, \"../../../migrations\"); err != nil {
		t.Fatalf(\"failed to run migrations: %v\", err)
	}

	return &PostgresContainer{
		Container: container,
		Pool:      pool,
		DSN:       dsn,
	}
}

// RunMigrationsFromFiles reads and executes all .up.sql files from the migrations directory
// This ensures the test database schema always matches the production schema
func RunMigrationsFromFiles(ctx context.Context, pool *pgxpool.Pool, migrationsDir string) error {
	// Find migration files
	entries, err := os.ReadDir(migrationsDir)
	if err != nil {
		return fmt.Errorf(\"read migrations dir: %w\", err)
	}

	// Filter and sort .up.sql files
	var migrationFiles []string
	for _, entry := range entries {
		if !entry.IsDir() && strings.HasSuffix(entry.Name(), \".up.sql\") {
			migrationFiles = append(migrationFiles, entry.Name())
		}
	}
	sort.Strings(migrationFiles)  // Ensures order: 001_xxx.up.sql, 002_xxx.up.sql, etc.

	// Execute each migration
	for _, filename := range migrationFiles {
		path := filepath.Join(migrationsDir, filename)
		content, err := os.ReadFile(path)
		if err != nil {
			return fmt.Errorf(\"read migration %s: %w\", filename, err)
		}

		if _, err := pool.Exec(ctx, string(content)); err != nil {
			return fmt.Errorf(\"execute migration %s: %w\", filename, err)
		}
	}

	return nil
}
```

### Migration Files Structure

The migration files are stored in the `migrations/` folder and used by both production and tests:

```
migrations/
‚îú‚îÄ‚îÄ 001_create_users.up.sql
‚îú‚îÄ‚îÄ 001_create_users.down.sql
‚îú‚îÄ‚îÄ 002_create_articles.up.sql
‚îú‚îÄ‚îÄ 002_create_articles.down.sql
‚îú‚îÄ‚îÄ 003_create_comments.up.sql
‚îú‚îÄ‚îÄ 003_create_comments.down.sql
‚îú‚îÄ‚îÄ 004_create_jobs.up.sql
‚îú‚îÄ‚îÄ 004_create_jobs.down.sql
‚îî‚îÄ‚îÄ 005_create_indexes.up.sql
```

**Example migration file:**

```sql
-- migrations/001_create_users.up.sql
CREATE TABLE IF NOT EXISTS users (
    id UUID PRIMARY KEY,
    email VARCHAR(255) UNIQUE NOT NULL,
    name VARCHAR(255) NOT NULL,
    role VARCHAR(50) NOT NULL,           -- Role validation done app-side
    active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMPTZ NOT NULL,
    updated_at TIMESTAMPTZ NOT NULL
);

CREATE INDEX IF NOT EXISTS idx_users_email ON users(email);
CREATE INDEX IF NOT EXISTS idx_users_role ON users(role);
```

**Benefits of using migration files for tests:**
- **Single source of truth**: Test schema always matches production
- **No schema drift**: Changes to migrations automatically apply to tests
- **Easier maintenance**: No need to update SQL in two places

### Repository Tests

```go
// internal/repository/user_repository_test.go
package repository_test

import (
	"context"
	"testing"
	"time"

	"github.com/google/uuid"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	"bulk-import-export/internal/domain"
	"bulk-import-export/internal/repository"
	"bulk-import-export/internal/repository/testutil"
)

func TestUserRepository_BulkInsertWithCTE(t *testing.T) {
	// Setup - starts real PostgreSQL container
	pg := testutil.SetupPostgresContainer(t)
	repo := repository.NewUserRepository(pg.Pool)
	ctx := context.Background()

	t.Run("all records inserted successfully", func(t *testing.T) {
		users := []domain.User{
			{
				ID:        uuid.New().String(),
				Email:     "user1@test.com",
				Name:      "User 1",
				Role:      "user",
				Active:    true,
				CreatedAt: time.Now(),
				UpdatedAt: time.Now(),
			},
			{
				ID:        uuid.New().String(),
				Email:     "user2@test.com",
				Name:      "User 2",
				Role:      "admin",
				Active:    true,
				CreatedAt: time.Now(),
				UpdatedAt: time.Now(),
			},
		}

		result, err := repo.BulkInsertWithCTE(ctx, users)

		require.NoError(t, err)
		assert.Equal(t, 2, result.Successful)
		assert.Empty(t, result.Errors)
	})

	t.Run("duplicate email returns error", func(t *testing.T) {
		// First insert
		users := []domain.User{
			{
				ID:        uuid.New().String(),
				Email:     "duplicate@test.com",
				Name:      "First",
				Role:      "user",
				Active:    true,
				CreatedAt: time.Now(),
				UpdatedAt: time.Now(),
			},
		}
		_, err := repo.BulkInsertWithCTE(ctx, users)
		require.NoError(t, err)

		// Second insert with same email
		duplicates := []domain.User{
			{
				ID:        uuid.New().String(),
				Email:     "duplicate@test.com", // Same email
				Name:      "Duplicate",
				Role:      "user",
				Active:    true,
				CreatedAt: time.Now(),
				UpdatedAt: time.Now(),
			},
		}

		result, err := repo.BulkInsertWithCTE(ctx, duplicates)

		require.NoError(t, err)
		assert.Equal(t, 0, result.Successful)
		assert.Len(t, result.Errors, 1)
		assert.Equal(t, "duplicate_email", result.Errors[0].Reason)
	})

	t.Run("invalid role rejected by check constraint", func(t *testing.T) {
		users := []domain.User{
			{
				ID:        uuid.New().String(),
				Email:     "invalid_role@test.com",
				Name:      "Invalid Role User",
				Role:      "superadmin", // Invalid role
				Active:    true,
				CreatedAt: time.Now(),
				UpdatedAt: time.Now(),
			},
		}

		result, err := repo.BulkInsertWithCTE(ctx, users)

		require.NoError(t, err)
		assert.Equal(t, 0, result.Successful)
		assert.Len(t, result.Errors, 1)
		assert.Equal(t, "invalid_role", result.Errors[0].Reason)
	})
}
```

### Running Tests

```bash
# Run all unit tests (fast, uses mocks)
go test ./internal/handler/... ./internal/service/... -v

# Run integration tests (slower, uses testcontainers)
go test ./internal/repository/... -v -tags=integration

# Run all tests
go test ./... -v

# Run tests with coverage
go test ./... -coverprofile=coverage.out
go tool cover -html=coverage.out
```

---

## E2E Test Scripts (bash + curl)

### Test Script Organization

```
scripts/
‚îú‚îÄ‚îÄ test-complete-api.sh      # Full API test suite
‚îú‚îÄ‚îÄ test-imports.sh           # Import-specific tests
‚îú‚îÄ‚îÄ test-exports.sh           # Export-specific tests
‚îú‚îÄ‚îÄ test-validation.sh        # Validation and error handling
‚îú‚îÄ‚îÄ test-performance.sh       # Performance benchmarks
‚îú‚îÄ‚îÄ test-idempotency.sh       # Idempotency tests
‚îú‚îÄ‚îÄ test-cancellation.sh      # Cancellation API tests
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ setup.sh              # Environment setup
    ‚îú‚îÄ‚îÄ wait-for-job.sh       # Job completion helper
    ‚îî‚îÄ‚îÄ cleanup.sh            # Test data cleanup
```

---

## Complete API Test Script

```bash
#!/bin/bash
# scripts/test-complete-api.sh

set -e

BASE_URL="http://localhost:8080"
TESTDATA_DIR="./testdata"

echo "=== Starting Complete API Testing ==="

# Start local file server for remote URL testing
python3 -m http.server 8081 --directory testdata &
FILE_SERVER_PID=$!
sleep 2

# Cleanup on exit
trap "kill $FILE_SERVER_PID 2>/dev/null" EXIT

# ============================================
# Test 1: Multipart Imports
# ============================================
echo ""
echo "=== Testing Multipart Imports ==="

# Import users (10,000 records)
USER_JOB=$(curl -s -X POST \
  -H "Idempotency-Key: test-users-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')
echo "‚úÖ User import job started: $USER_JOB"

# Import articles (15,000 records)
ARTICLE_JOB=$(curl -s -X POST \
  -H "Idempotency-Key: test-articles-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/articles_huge.ndjson" \
  -F "resource=articles" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')
echo "‚úÖ Article import job started: $ARTICLE_JOB"

# ============================================
# Test 2: JSON Import with Remote URL
# ============================================
echo ""
echo "=== Testing Remote URL Imports ==="

# Import comments via remote URL (20,000 records)
COMMENT_JOB=$(curl -s -X POST \
  -H "Content-Type: application/json" \
  -H "Idempotency-Key: test-remote-comments-$(date +%s)" \
  -d '{
    "resource": "comments",
    "file_url": "http://localhost:8081/comments_huge.ndjson",
    "format": "ndjson"
  }' \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')
echo "‚úÖ Comment import job (remote URL) started: $COMMENT_JOB"

# ============================================
# Test 3: Monitor Import Progress
# ============================================
echo ""
echo "=== Monitoring Import Progress ==="
sleep 10

echo "üìä User import status:"
curl -s "${BASE_URL}/v1/imports/${USER_JOB}" | jq '{job_id, status, processed_records, successful_records, error_records}'

echo "üìä Article import status:"
curl -s "${BASE_URL}/v1/imports/${ARTICLE_JOB}" | jq '{job_id, status, processed_records, successful_records, error_records}'

echo "üìä Comment import status:"
curl -s "${BASE_URL}/v1/imports/${COMMENT_JOB}" | jq '{job_id, status, processed_records, successful_records, error_records}'

# ============================================
# Test 4: Streaming Exports
# ============================================
echo ""
echo "=== Testing Streaming Exports ==="

echo "üì§ Streaming users (first 5 records):"
curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson" | head -5

echo ""
echo "üì§ Streaming articles (first 3 records):"
curl -s "${BASE_URL}/v1/exports?resource=articles&format=ndjson" | head -3

echo ""
echo "üì§ Streaming comments (first 3 records):"
curl -s "${BASE_URL}/v1/exports?resource=comments&format=ndjson" | head -3

# ============================================
# Test 5: Async Exports
# ============================================
echo ""
echo "=== Testing Async Exports ==="

# Start async export with filters
USER_EXPORT_JOB=$(curl -s -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "resource": "users",
    "format": "ndjson",
    "filters": {
      "role": "admin"
    },
    "fields": ["id", "email", "name", "role"]
  }' \
  "${BASE_URL}/v1/exports" | jq -r '.job_id')
echo "‚úÖ Async export job started: $USER_EXPORT_JOB"

# Wait for completion and check status
sleep 5
echo "üìä Export job status:"
curl -s "${BASE_URL}/v1/exports/${USER_EXPORT_JOB}" | jq '.'

# ============================================
# Test 6: Idempotency
# ============================================
echo ""
echo "=== Testing Idempotency ==="

IDEMPOTENCY_KEY="test-duplicate-$(date +%s)"

echo "üîÑ First request with idempotency key..."
FIRST_JOB=$(curl -s -X POST \
  -H "Idempotency-Key: $IDEMPOTENCY_KEY" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')

echo "üîÑ Second request with same key (should return same job)..."
SECOND_JOB=$(curl -s -X POST \
  -H "Idempotency-Key: $IDEMPOTENCY_KEY" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')

if [ "$FIRST_JOB" = "$SECOND_JOB" ]; then
  echo "‚úÖ Idempotency working correctly: $FIRST_JOB"
else
  echo "‚ùå Idempotency failed: $FIRST_JOB != $SECOND_JOB"
  exit 1
fi

# ============================================
# Test 7: Cancellation
# ============================================
echo ""
echo "=== Testing Job Cancellation ==="

# Start a large import
CANCEL_JOB=$(curl -s -X POST \
  -H "Idempotency-Key: test-cancel-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')
echo "‚úÖ Started job for cancellation test: $CANCEL_JOB"

# Wait a moment then cancel
sleep 2
echo "üõë Cancelling job..."
CANCEL_RESPONSE=$(curl -s -X POST "${BASE_URL}/v1/imports/${CANCEL_JOB}/cancel")
CANCEL_STATUS=$(echo $CANCEL_RESPONSE | jq -r '.status')

if [ "$CANCEL_STATUS" = "cancelled" ]; then
  echo "‚úÖ Job cancelled successfully"
  echo "$CANCEL_RESPONSE" | jq '{status, processed_records, successful_records}'
else
  echo "‚ö†Ô∏è Cancellation response: $CANCEL_RESPONSE"
fi

# ============================================
# Test 8: Import Job Listing
# ============================================
echo ""
echo "=== Testing Job Listing ==="

echo "üìã Listing all import jobs:"
curl -s "${BASE_URL}/v1/imports?limit=5" | jq '.jobs[] | {job_id, resource_type, status}'

echo ""
echo "üìã Listing processing jobs only:"
curl -s "${BASE_URL}/v1/imports?status=processing&limit=5" | jq '.jobs[] | {job_id, resource_type, status}'

# ============================================
# Test 9: Performance Measurement
# ============================================
echo ""
echo "=== Performance Testing ==="

echo "üöÄ Testing streaming export performance..."
START_TIME=$(date +%s)
RECORD_COUNT=$(curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson" | wc -l)
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

if [ $DURATION -gt 0 ]; then
  RPS=$((RECORD_COUNT / DURATION))
  echo "üìä Exported $RECORD_COUNT records in ${DURATION}s (${RPS} records/sec)"
else
  echo "üìä Exported $RECORD_COUNT records in <1s"
fi

echo ""
echo "=== All Tests Completed ==="
```

---

## Import Tests Script

```bash
#!/bin/bash
# scripts/test-imports.sh

set -e

BASE_URL="http://localhost:8080"
TESTDATA_DIR="./testdata"

echo "=== Import Tests ==="

# Test 1: CSV Import (Users)
echo ""
echo "Test 1: CSV Import (Users)"
RESPONSE=$(curl -s -X POST \
  -H "Idempotency-Key: import-test-csv-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports")
echo "Response: $RESPONSE"
JOB_ID=$(echo $RESPONSE | jq -r '.job_id')

# Wait and check status
sleep 5
echo "Status:"
curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq '.'

# Test 2: NDJSON Import (Articles)
echo ""
echo "Test 2: NDJSON Import (Articles)"
RESPONSE=$(curl -s -X POST \
  -H "Idempotency-Key: import-test-ndjson-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/articles_huge.ndjson" \
  -F "resource=articles" \
  "${BASE_URL}/v1/imports")
echo "Response: $RESPONSE"

# Test 3: Invalid Resource Type
echo ""
echo "Test 3: Invalid Resource Type (should fail)"
curl -s -X POST \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=invalid" \
  "${BASE_URL}/v1/imports" | jq '.'

# Test 4: Missing File
echo ""
echo "Test 4: Missing File (should fail)"
curl -s -X POST \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq '.'

echo ""
echo "=== Import Tests Completed ==="
```

---

## Export Tests Script

```bash
#!/bin/bash
# scripts/test-exports.sh

set -e

BASE_URL="http://localhost:8080"

echo "=== Export Tests ==="

# Test 1: Streaming Export (NDJSON)
echo ""
echo "Test 1: Streaming Export (NDJSON) - First 10 records"
curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson" | head -10

# Test 2: Streaming Export with Field Selection
echo ""
echo "Test 2: Streaming Export with Field Selection"
curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson&fields=id,email,name" | head -5

# Test 3: Streaming Export with Filter
echo ""
echo "Test 3: Streaming Export with Filter (role=admin)"
curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson&filter[role]=admin" | head -5

# Test 4: Async Export
echo ""
echo "Test 4: Async Export"
RESPONSE=$(curl -s -X POST \
  -H "Content-Type: application/json" \
  -d '{
    "resource": "articles",
    "format": "ndjson"
  }' \
  "${BASE_URL}/v1/exports")
echo "Response: $RESPONSE"
JOB_ID=$(echo $RESPONSE | jq -r '.job_id')

# Wait for completion
sleep 5
echo "Status:"
curl -s "${BASE_URL}/v1/exports/${JOB_ID}" | jq '.'

# Test 5: Download Async Export
echo ""
echo "Test 5: Download Async Export (first 5 lines)"
curl -s "${BASE_URL}/v1/exports/${JOB_ID}/download" | head -5

# Test 6: Invalid Resource
echo ""
echo "Test 6: Invalid Resource (should fail)"
curl -s "${BASE_URL}/v1/exports?resource=invalid" | jq '.'

echo ""
echo "=== Export Tests Completed ==="
```

---

## Validation Tests Script

```bash
#!/bin/bash
# scripts/test-validation.sh

set -e

BASE_URL="http://localhost:8080"

echo "=== Validation Tests ==="

# Create temp file with invalid data
TEMP_FILE=$(mktemp)
cat > $TEMP_FILE << 'EOF'
id,email,name,role,active,created_at,updated_at
550e8400-e29b-41d4-a716-446655440001,valid@example.com,Valid User,user,true,2024-01-15T10:00:00Z,2024-01-15T10:00:00Z
550e8400-e29b-41d4-a716-446655440002,invalid-email,Invalid Email User,user,true,2024-01-15T10:00:00Z,2024-01-15T10:00:00Z
550e8400-e29b-41d4-a716-446655440003,valid2@example.com,Valid User 2,superadmin,true,2024-01-15T10:00:00Z,2024-01-15T10:00:00Z
550e8400-e29b-41d4-a716-446655440004,valid@example.com,Duplicate Email,user,true,2024-01-15T10:00:00Z,2024-01-15T10:00:00Z
EOF

# Test: Import with mixed valid/invalid data
echo ""
echo "Test: Import with mixed valid/invalid data"
RESPONSE=$(curl -s -X POST \
  -H "Idempotency-Key: validation-test-$(date +%s)" \
  -F "file=@${TEMP_FILE}" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports")
echo "Response: $RESPONSE"
JOB_ID=$(echo $RESPONSE | jq -r '.job_id')

# Wait for completion
echo "Waiting for job to complete..."
sleep 10

# Check final status with errors
echo ""
echo "Final status with errors:"
curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq '.'

# Cleanup
rm $TEMP_FILE

echo ""
echo "=== Validation Tests Completed ==="
```

---

## Performance Tests Script

```bash
#!/bin/bash
# scripts/test-performance.sh

set -e

BASE_URL="http://localhost:8080"
TESTDATA_DIR="./testdata"

echo "=== Performance Tests ==="

# Test 1: Import Performance (10K users)
echo ""
echo "Test 1: Import Performance (10,000 users)"
START_TIME=$(date +%s.%N)

JOB_ID=$(curl -s -X POST \
  -H "Idempotency-Key: perf-test-$(date +%s)" \
  -F "file=@${TESTDATA_DIR}/users_huge.csv" \
  -F "resource=users" \
  "${BASE_URL}/v1/imports" | jq -r '.job_id')

# Wait for completion
while true; do
  STATUS=$(curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq -r '.status')
  if [ "$STATUS" = "completed" ] || [ "$STATUS" = "failed" ]; then
    break
  fi
  sleep 1
done

END_TIME=$(date +%s.%N)
DURATION=$(echo "$END_TIME - $START_TIME" | bc)
echo "‚úÖ Import completed in ${DURATION}s"

# Get final stats
curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq '{
  total_records,
  successful_records,
  error_records,
  duration_seconds: (.completed_at | fromdateiso8601) - (.started_at | fromdateiso8601)
}'

# Test 2: Export Performance (Streaming)
echo ""
echo "Test 2: Export Performance (Streaming all users)"
START_TIME=$(date +%s.%N)
RECORD_COUNT=$(curl -s "${BASE_URL}/v1/exports?resource=users&format=ndjson" | wc -l)
END_TIME=$(date +%s.%N)
DURATION=$(echo "$END_TIME - $START_TIME" | bc)
RPS=$(echo "scale=2; $RECORD_COUNT / $DURATION" | bc)
echo "‚úÖ Exported $RECORD_COUNT records in ${DURATION}s (${RPS} records/sec)"

# Test 3: Memory Usage (should remain constant)
echo ""
echo "Test 3: Memory baseline"
echo "Check application memory usage via Grafana or 'ps aux | grep bulk-import'"

echo ""
echo "=== Performance Tests Completed ==="
```

---

## Utility Scripts

### Wait for Job Script

```bash
#!/bin/bash
# scripts/utils/wait-for-job.sh

JOB_ID=$1
BASE_URL=${2:-"http://localhost:8080"}
TIMEOUT=${3:-300}  # 5 minutes default

if [ -z "$JOB_ID" ]; then
  echo "Usage: wait-for-job.sh <job_id> [base_url] [timeout_seconds]"
  exit 1
fi

echo "Waiting for job $JOB_ID to complete (timeout: ${TIMEOUT}s)..."

START_TIME=$(date +%s)
while true; do
  STATUS=$(curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq -r '.status')
  
  if [ "$STATUS" = "completed" ]; then
    echo "‚úÖ Job completed successfully"
    curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq '.'
    exit 0
  elif [ "$STATUS" = "failed" ]; then
    echo "‚ùå Job failed"
    curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq '.'
    exit 1
  fi
  
  CURRENT_TIME=$(date +%s)
  ELAPSED=$((CURRENT_TIME - START_TIME))
  
  if [ $ELAPSED -ge $TIMEOUT ]; then
    echo "‚è±Ô∏è Timeout waiting for job"
    exit 2
  fi
  
  # Show progress
  PROCESSED=$(curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq -r '.processed_records // 0')
  TOTAL=$(curl -s "${BASE_URL}/v1/imports/${JOB_ID}" | jq -r '.total_records // 0')
  echo "  Progress: $PROCESSED / $TOTAL (${ELAPSED}s elapsed)"
  
  sleep 2
done
```

### Setup Script

```bash
#!/bin/bash
# scripts/utils/setup.sh

echo "Setting up test environment..."

# Ensure testdata directory exists
mkdir -p testdata

# Move test data files if they exist in root
for file in users_huge.csv articles_huge.ndjson comments_huge.ndjson; do
  if [ -f "$file" ] && [ ! -f "testdata/$file" ]; then
    mv "$file" testdata/
    echo "Moved $file to testdata/"
  fi
done

# Verify files exist
echo ""
echo "Test data files:"
ls -lh testdata/*.csv testdata/*.ndjson 2>/dev/null || echo "No test data files found"

echo ""
echo "Setup complete!"
```

---

## Running Tests

```bash
# Make scripts executable
chmod +x scripts/*.sh scripts/utils/*.sh

# Run all tests
./scripts/test-complete-api.sh

# Run specific test suites
./scripts/test-imports.sh
./scripts/test-exports.sh
./scripts/test-validation.sh
./scripts/test-performance.sh
```

---

## Related Documents

- [API Specification](./api-specification.md) - Endpoint details
- [Development Setup](./development-setup.md) - Starting the server
- [Validation Strategy](./validation-strategy.md) - Error handling
